{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPfochMtiRZzPTEjuOMMbRB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dinakajoy/UsingLLMs-RAG-course/blob/main/4_OpenAI_API_Intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction To OpenAI API"
      ],
      "metadata": {
        "id": "K_gRp7-J6GUx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "meGtOZmS6POS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive to access files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TnvD_AAbh8a",
        "outputId": "a9629408-5d42-40ff-b12a-ee83571c35d4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/RAG\\ Course"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjO5NGutb7ef",
        "outputId": "1d8acc6a-3e96-4d10-c46e-c923acc7925c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/RAG Course\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "api_key = userdata.get('openai_api')"
      ],
      "metadata": {
        "id": "PmhrcP4t6MEC"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install openai library\n",
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_x4thlhdILj",
        "outputId": "d04a9177-7a3a-46c6-f3cf-d83958ef6640"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.100.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.14.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "from openai import OpenAI\n",
        "from IPython.display import Markdown, display\n",
        "import base64\n",
        "import os"
      ],
      "metadata": {
        "id": "lZrb4e67eOOV"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup model\n",
        "MODEL = \"gpt-4o\""
      ],
      "metadata": {
        "id": "mY67bJpYekQb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# connect to the OpenAI APi\n",
        "client = OpenAI(api_key=api_key)"
      ],
      "metadata": {
        "id": "5uBI-_akeqvy"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating Text With OpenAI"
      ],
      "metadata": {
        "id": "BcuIz7nAe_z9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the system prompts\n",
        "system_prompt = \"You are a Kendrick Lamar\"\n",
        "system_prompt2 = \"You are a poet\""
      ],
      "metadata": {
        "id": "XIHgkrHLe6-X"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the user prompt\n",
        "user_prompt = \"Tell me a story\""
      ],
      "metadata": {
        "id": "-05ZH1wWgrDy"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`system prompt` guide the assistant's behaviour by providing context or instructions"
      ],
      "metadata": {
        "id": "l6MVbsJ1fkoQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Geenerate text with OpenAI\n",
        "response = client.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": user_prompt},\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "kDg4DSlRf62Z"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the generate story\n",
        "display(Markdown(response.choices[0].message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "id": "2R_1PIl9hFP7",
        "outputId": "d322de55-382e-4e66-fa17-e913115fd53e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Once upon a time in the vibrant city of Compton, where music was the language of the streets and dreams floated like melodies on the breeze, there was a young boy named Jamal. Jamal had rhythm in his heart and poetry in his soul, with aspirations of making his voice heard far beyond the confines of his neighborhood.\n\nEvery day after school, Jamal would sit on his porch with a notebook filled with lyrics and a heart full of hope. The beats from passing cars were his background music, the chatter of his neighbors his inspiration. He had a mentor, Mr. Johnson, the old jazz musician from two houses down, who always said, \"Jamal, your words are like notes on a trumpet, but you've got to make 'em dance.\"\n\nJamal took those words to heart. He started turning his poetry into rap, blending the stories of his life with rhythms that echoed the pulse of his community. His best friend Lisa had a knack for beatboxing, and together they spent countless afternoons crafting songs that spoke of dreams, struggles, and resilience.\n\nOne day, a local music competition was announced, promising studio time and a small record deal to the winner. Jamal saw it as the opportunity he'd been waiting for. He and Lisa poured themselves into their music, bringing their stories to life with raw energy and heartfelt sincerity. Their entry, a powerful blend of hope and reality, caught the attention of everyone who heard it.\n\nOn the day of the competition, the small venue was packed, buzzing with anticipation. Jamal and Lisa gave it their all on stage, their chemistry undeniable, their message clear and profound. When the winner was announced, they stood there, hearts racing, and heard their names called out.\n\nWith the prize they won, Jamal and Lisa recorded their first track, capturing the essence of their journey and the spirit of Compton. Their music spread like wildfire, resonating with people from all walks of life. Jamal realized that his dreams were no longer just his—they belonged to everyone who ever yearned for something greater, who believed in the power of words and beats.\n\nAnd so, with every verse and every rhythm, Jamal told not just his own story, but the story of a community, of dreams nurtured in concrete jungles, and of voices that refused to be silenced."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explanation:\n",
        "\n",
        "* **System Prompt**: Sets the context or persona for the assistant.\n",
        "* **User Prompt**: Specifies the task or question.\n",
        "* **Messages**: A list of interactions leading up to the current request.\n",
        "* **Model**: The AI model used for generating the response."
      ],
      "metadata": {
        "id": "9rjpWHcknV4D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Generation With Parameters\n",
        "\n",
        "We can influence the creativity and randomness of the generated text by adjusting parameters like temperature and top_p"
      ],
      "metadata": {
        "id": "8j2jhr1Qm7zV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate text with adjusted parameters\n",
        "response = client.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_prompt2},\n",
        "        {\"role\": \"user\", \"content\": user_prompt},\n",
        "    ],\n",
        "    temperature=1.2,\n",
        "    top_p=1.0,\n",
        "    presence_penalty=0.0,\n",
        "    frequency_penalty=0,\n",
        ")\n",
        "\n",
        "# Display the output\n",
        "display(Markdown(response.choices[0].message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "VXXNb2dtnTPD",
        "outputId": "00d35b8f-cd1c-49f2-c9a5-0d823bbb0741"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The image is a slide titled \"Overview: RAG with OpenAI GPT Models.\" On the left, there's an illustration of three characters: one is an AI robot, interacting with a person through speech bubbles, and another person is at a laptop pondering. On the right, a bulleted list highlights topics:\n\n- Data Conversion Mastery\n- Advanced OCR with GPT\n- Building a Retrieval System That Works\n- Seamless Integration of Retrieval and Generation\n- Fine-Tuning with Prompt Engineering\n\nThe layout suggests a focus on AI applications and strategies."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Key Concepts:\n",
        "\n",
        "* **Temperature:** This parameter controls the randomness of the model's output. A higher temperature (e.g., 1.2) makes the output more random, while a lower temperature (e.g., 0.2) makes it more deterministic.\n",
        "* **Top_p (Nucleus Sampling):** This parameter limits the model's token selection to a subset of the most probable tokens that sum up to the top_p probability. For example, top_p=0.9 means only the tokens comprising the top 90% probability mass are considered.\n",
        "* **Presence and Frequency Penalties:** These parameters adjust the likelihood of the model repeating the same lines or introducing new topics. A higher presence penalty discourages the model from introducing new topics, while a higher frequency penalty discourages repetition."
      ],
      "metadata": {
        "id": "QEbfPw5Vhwmk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interacting With Images\n",
        "\n",
        "We can also the OpenAI API to generate descriptions or analyze images"
      ],
      "metadata": {
        "id": "0FOMP3jYh1De"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "3LM21a_y56Oi"
      },
      "outputs": [],
      "source": [
        "# Define the URL of an image we will use\n",
        "url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Describe user content with an image. We provide both text and image url\n",
        "user_content = [\n",
        "    {\"type\": \"text\", \"text\": \"Describe the scene in the image.\"},\n",
        "    {\"type\": \"image_url\", \"image_url\": {\"url\": url, \"detail\": \"high\"}},\n",
        "]"
      ],
      "metadata": {
        "id": "vMUliOcmhmvL"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pass it to the model\n",
        "response = client.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": user_content},\n",
        "    ]\n",
        ")\n",
        "display(Markdown(response.choices[0].message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "Ex_mhZgzh-Ry",
        "outputId": "d8a6848c-0891-46f8-f90a-a7eed129e2b2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The image depicts a serene natural landscape. There is a wooden boardwalk that stretches into the distance, surrounded by lush green grass and bushes. The sky is bright and blue with scattered clouds, creating a peaceful and open atmosphere. The scene suggests a gentle, sunny day in a countryside or park setting."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explanation of Key Concepts\n",
        "\n",
        "* **Image Processing with OpenAI:** OpenAI's models can analyze and generate descriptions for images when provided with appropriate inputs.\n",
        "\n",
        "* **Content Types:** The assistant can handle different types of content, including text and images, by specifying the type in the content dictionary."
      ],
      "metadata": {
        "id": "kUpqtPCMj8uM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use Base64 Encoded Encoded Images\n",
        "\n",
        "We can provide an image directly to our model in Base64"
      ],
      "metadata": {
        "id": "tnc1sjavkAU9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Image details\n",
        "file_name = \"Overview-RAG-with-OpenAI-GPT-Models.png\"\n",
        "file_path = os.path.join(os.getcwd(), file_name)\n",
        "\n",
        "# Read the image and convertto base64\n",
        "with open(file_path, \"rb\") as image_file:\n",
        "    image_base64 = base64.b64encode(image_file.read()).decode('utf-8')"
      ],
      "metadata": {
        "id": "_z-njEcrj0sA"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the user prompt\n",
        "user_prompt = [\n",
        "    {\"type\": \"text\", \"text\": \"Describe the scene in the image.\"},\n",
        "    {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_base64}\", \"detail\": \"high\"}},\n",
        "]"
      ],
      "metadata": {
        "id": "Z7XZBF6alw5o"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a response using the Base64-encoded image\n",
        "response = client.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": user_prompt},\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Display the response\n",
        "display(Markdown(response.choices[0].message.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "nE9n36Wol-j3",
        "outputId": "fe764a0e-9077-4b46-d9e7-46b1dbc46130"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The image depicts an educational or instructional presentation slide titled \"Overview: RAG with OpenAI GPT Models.\" On the left side, there are colorful illustrations. One features a human interacting with an AI robot, symbolized by speech bubbles, and the robot has a small \"AI\" tag. Below, another illustration shows a person thinking while working on a laptop.\n\nOn the right side, there is a list of topics highlighted in different colors:\n\n1. Data Conversion Mastery\n2. Advanced OCR with GPT\n3. Building a Retrieval System That Works\n4. Seamless Integration of Retrieval and Generation\n5. Fine-Tuning with Prompt Engineering\n\nThe slide is part of a presentation, indicated by navigation buttons at the top for going to the previous lesson or completing and continuing the current one."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explanation of Key Concepts\n",
        "\n",
        "* **Base64 Encoding**: Base64 is a method for encoding binary data into ASCII characters, making it safe to include in text-based formats like JSON.\n",
        "\n",
        "* **Data URIs**: By using a data URI scheme (data:image/jpeg;base64,...), we can include image data directly in the URL field, which is especially useful when the image is not hosted online."
      ],
      "metadata": {
        "id": "gdLkjvg0mTHv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U9w9f82UmPvL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}